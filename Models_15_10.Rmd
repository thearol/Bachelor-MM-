---
title: "Models"
author: "Thea Rolskov Sloth"
date: "15/10/2019"
output: html_document
---

#Getting packages
```{r loading packages, include = FALSE}
library(pacman)
p_load(brms, tidyverse, tidybayes, ggplot2, LaplacesDemon, rethinking, tidyr, reshape2, tibble, plotly, jpeg, tm, ggrepel, utils, boot, Hmisc)
```

#Setting directory
```{r}
setwd("~/Bachelor-MM-/") #TRS
```

#Loading data
```{r}
data_ib <- read.csv("implicit_bias/data_ib.csv")[,2:12]
data_eb <- read.csv("explicit_bias/eb_results.csv")[, 2:6]
data_db <- read.csv("decision_bias/disagree_sensitivity_db_long.csv")[, 2:44]
data_db_all <- read.csv("decision_bias/data_db_all.csv")
```


#IMPLICIT BIAS

```{r implicit model, condition}
#Tranforming condition to a factor
data_ib$condition <- as.factor(data_ib$condition)

#to figure out which prior we need to make
get_prior(rt_log ~ condition + (condition|ID), data = data_ib)

#Defining a prior 
prior_ib1 = c(prior(normal(-0.4, 0.2), class = "Intercept"), 
          prior(normal(0, 0.2), class = "b"), 
          prior(normal(0, 0.2), class = "sigma"),
          prior(normal(0, 0.1), class = "sd"))

#Implicit model
model_ib1_prior <- brm(rt_log ~ condition + (condition|ID),
                    data = data_ib,
                    family = gaussian(),
                    prior = prior_ib1,
                    sample_prior = "only",
                    cores = 2,
                    chains = 2)

pp_check(model_ib1_prior, nsamples = 100) #Doing a predictive prior check to test priors

model_ib1 <- brm(rt_log ~ condition + (condition|ID),
                    data = data_ib,
                    family = gaussian(),
                    prior = prior_ib1,
                    sample_prior = TRUE,
                    iter = 5000,
                    warmup = 2000,
                    cores = 4,
                    chains = 4)

summary(model_ib1)

#plotting
plot(model_ib1)

marginal_effects(model_ib1)
```



##Difference between gender and condition, interaction
```{r model, condition + gender}
#to figure out which prior I need to make 
get_prior(rt ~  condition*gender + (condition|ID), data = data_ib)

#Defining a prior
prior_ib2 = c(prior(normal(-0.4, 0.2), class = "Intercept"),
              prior(normal(0, 0.2), class = "b"),
              prior(normal(0, 0.2), class = "sigma"),
              prior(normal(0, 0.1), class = "sd"))

#Implicit model
model_ib2_prior <- brm(rt_log ~ condition*gender + (condition|ID),
                    data = data_ib,
                    family = gaussian(),
                    prior = prior_ib2,
                    sample_prior = "only",
                    cores = 2,
                    chains = 2)

pp_check(model_ib2_prior, nsamples = 100) #Doing a predictive prior check to test priors


model_ib2 <- brm(rt_log ~ condition*gender + (condition|ID),
                    data = data_ib,
                    family = gaussian(),
                    prior = prior_ib2,
                    sample_prior = TRUE,
                    iter = 5000,
                    warmup = 2000,
                    cores = 4,
                    chains = 4)

summary(model_ib2) 

#plotting
marginal_effects(model_ib2)

plot(model_ib2)

```



##Implicit bias, Comparing models
```{r waic, implicit}
waic(model_ib1, model_ib2)

waic1 <- waic(model_ib1)
waic2 <- waic(model_ib2)

loo_compare(waic1, waic2)
```


##Implicit bias, hypothesis testing
```{r}
hypothesis(model_ib1, "condition1 > 0")
hypothesis(model_ib2, "condition1 > condition1 + condition1:genderMale")
```

##Plotting, implicit bias

###H2.1.1
```{r prepare predictions}
nd_ib1 <- expand.grid(tibble(
         ID = NA, 
         condition=factor(0:1) %>% 
           rep(., times = 10)))

pred_ib1 <-
  predict(model_ib1, newdata = nd_ib1) %>%  # we can use the same nd data from last time
  as_tibble() %>%
  bind_cols(nd_ib1)

pred_ib1$Estimate <- inv.logit(pred_ib1$Estimate)
pred_ib1_mean <- pred_ib1 %>% group_by(condition) %>% summarise(mean_prediction = mean(Estimate))

pred_ib1$condition <- ifelse(pred_ib1$condition == 0, "Congruent", "Incongruent")


data_ib_for_plot <- data_ib
data_ib_for_plot$condition <- ifelse(data_ib_for_plot$condition == 0, "Congruent", "Incongruent")
pred_ib1_mean$condition <- ifelse(pred_ib1_mean$condition == 0, "Congruent", "Incongruent")


```


```{r H2.1.1 plot}
#create the plot
H2.1.1 <- ggplot(data_ib_for_plot, aes(x = condition, y = rt)) +
  labs(x = "Condition", y = "Reaction time", title = "Hypothesis 2.1.1") +
  geom_violin(aes(x = condition, Estimate, fill = condition) , data = pred_ib1, width = 0.5, alpha = 0.4) + 
  theme(legend.position = "none", panel.grid.minor = element_blank()) + 
  geom_point(aes(x = condition, y = mean_prediction), data = pred_ib1_mean, size = 2) + 
  scale_fill_manual(values=c("orange", "blue")) +
  theme(plot.title = element_text(hjust = 0.5))
H2.1.1
```

###H2.2.1
```{r prepare predictions}
nd_ib2 <- expand.grid(tibble(
         gender=factor(0:1) %>% 
           rep(., times = 10),
         ID = NA, 
         condition=factor(0:1) %>% 
           rep(., times = 10)))

nd_ib2$gender <- ifelse(nd_ib2$gender == 0, "Male", "Female")

pred_ib2 <-
  predict(model_ib2, newdata = nd_ib2) %>%  # we can use the same nd data from last time
  as_tibble() %>%
  bind_cols(nd_ib2)

pred_ib2$Estimate_prop <- inv.logit(pred_ib1$Estimate)

pred_ib2$dif <- NA
pred_ib2$dif[pred_ib2$gender == "Male"] <- pred_ib2$Estimate[pred_ib2$condition == 1 & pred_ib2$gender == "Male"] - pred_ib2$Estimate[pred_ib2$condition == 0 & pred_ib2$gender == "Male"]

pred_ib2$dif[pred_ib2$gender == "Female"] <- pred_ib2$Estimate[pred_ib2$condition == 1 & pred_ib2$gender == "Female"] - pred_ib2$Estimate[pred_ib2$condition == 0 & pred_ib2$gender == "Female"]

pred_ib2_mean <- pred_ib2 %>% group_by(condition, gender) %>% summarise(mean_prediction = mean(Estimate))

pred_ib2$condition <- ifelse(pred_ib2$condition == 0, "Congruent", "Incongruent")



```


```{r H2.2.1 plot}
#create the plot
H2.2.1 <- ggplot(pred_ib2, aes(x = gender, y = dif, fill = gender)) +
  labs(x = "Gender", y = "Difference in reaction time (log)", title = "Hypothesis 2.2.1") +
  geom_bar(stat="summary", position = position_dodge2())  + 
geom_errorbar(aes(ymin=0, ymax=dif + Est.Error),width=.2,position=position_dodge(.9)) + 
  #geom_point(aes(x = condition, y = Estimate_prop, fill = gender), data = pred_ib2, size = 2, position = position_dodge2(width= 0.1)) + 
  scale_fill_manual(values=c("orange", "blue")) +
  theme(plot.title = element_text(hjust = 0.5))
H2.2.1


```

```{r}


H2.2.1_lines <- ggplot(pred_ib2, aes(x = condition, y = Estimate, group = gender, color = gender)) + 
  scale_color_manual(values=c("orange", "blue"), name = "Gender") + 
  stat_summary(fun.data = "mean_cl_boot", color = "black", size = 1.5, geom = "point") + 
  stat_summary(fun.y = mean, geom="line") + 
  labs(x = "Condition", y = "Reaction time (log)", title = "Hypothesis 2.2.1")

H2.2.1_lines


```



#EXPLICIT BIAS

Lav en model, der viser om mænd er mere sexistiske. 

Men det informerer ikkke spørgsmålet, om der et kønsbias synderligt, det den kun er rettet imod at beskrive kønnenes indstilling til kvinder?  

##Overall_score

```{r overall score, models}
#to figure out which prior we need to make
get_prior(overall_score ~ gender + (1|ID), data = data_eb)

#Defining a prior, mean set to 2.5 because best conceptual meaning
prior_eb1.1 = c(prior(normal(2.5, 0.5), class = "Intercept"), 
          prior(normal(0, 0.5), class = "b"), 
          prior(normal(0, 0.5), class = "sigma"),
          prior(normal(0, 0.1), class = "sd"))

#try and make a prior with mean set to 2 as it might make the model better
prior_eb1.2 = c(prior(normal(2, 0.5), class = "Intercept"), 
          prior(normal(0, 0.5), class = "b"), 
          prior(normal(0, 0.5), class = "sigma"),
          prior(normal(0, 0.1), class = "sd"))



#Implicit models - check of both priors
model_eb1.1_prior <- brm(overall_score ~ gender + (1|ID),
                    data = data_eb,
                    family = gaussian(),
                    prior = prior_eb1.1,
                    sample_prior = "only",
                    cores = 2,
                    chains = 2)

model_eb1.2_prior <- brm(overall_score ~ gender + (1|ID),
                    data = data_eb,
                    family = gaussian(),
                    prior = prior_eb1.2,
                    sample_prior = "only",
                    cores = 2,
                    chains = 2)

#prior check for both priors
pp_check(model_eb1.1_prior, nsamples = 100) #Doing a predictive prior check to test priors

pp_check(model_eb1.2_prior, nsamples = 100)

#models with both priors 
model_eb1.1 <- brm(overall_score ~ gender + (1|ID),
                    data = data_eb,
                    family = gaussian(),
                    prior = prior_eb1.1,
                    sample_prior = TRUE,
                    iter = 5000,
                    warmup = 2000,
                    cores = 4,
                    chains = 4, 
                    control = list(adapt_delta = 0.9))

model_eb1.2 <- brm(overall_score ~ gender + (1|ID),
                    data = data_eb,
                    family = gaussian(),
                    prior = prior_eb1.2,
                    sample_prior = TRUE,
                    iter = 5000,
                    warmup = 2000,
                    cores = 4,
                    chains = 4, 
                    control = list(adapt_delta = 0.9)) 

waic(model_eb1.1, model_eb1.2)

summary(model_eb1.2)

marginal_effects(model_eb1.2)

summary(model_eb1.1)

marginal_effects(model_eb1.1)

plot(model_eb1.1)

#we will go with model eb1.1
```

##Benevolence predicted from gender and hostile score

```{r}
get_prior(benevolent_score ~ gender*hostile_score + (1|ID), data = data_eb)

#Defining a prior, mean set to 2.5 because best conceptual meaning
prior_eb2 = c(prior(normal(2.5, 0.5), class = "Intercept"), 
          prior(normal(0, 0.5), class = "b"), 
          prior(normal(0, 0.5), class = "sigma"),
          prior(normal(0, 0.1), class = "sd"))

model_eb2_prior <- brm(benevolent_score ~ gender*hostile_score + (1|ID),
                    data = data_eb,
                    family = gaussian(),
                    prior = prior_eb2,
                    sample_prior = "only",
                    cores = 2,
                    chains = 2)

#prior check for both priors
pp_check(model_eb2_prior, nsamples = 100) #Doing a predictive prior check to test priors

#model
model_eb2 <- brm(benevolent_score ~ gender*hostile_score + (1|ID),
                    data = data_eb,
                    family = gaussian(),
                    prior = prior_eb2,
                    sample_prior = TRUE,
                    iter = 5000,
                    warmup = 2000,
                    cores = 4,
                    chains = 4, 
                    control = list(adapt_delta = 0.9))

summary(model_eb2)

#Plotting
marginal_effects(model_eb2)

plot(model_eb2)
```


##Hostility predicted from gender and benevolent score

```{r}
get_prior(hostile_score ~ gender*benevolent_score + (1|ID), data = data_eb)

#Defining a prior, mean set to 2.5 because best conceptual meaning
prior_eb3 = c(prior(normal(2.5, 0.5), class = "Intercept"), 
          prior(normal(0, 0.5), class = "b"), 
          prior(normal(0, 0.5), class = "sigma"),
          prior(normal(0, 0.1), class = "sd"))

model_eb3_prior <- brm(hostile_score ~ gender*benevolent_score + (1|ID),
                    data = data_eb,
                    family = gaussian(),
                    prior = prior_eb3,
                    sample_prior = "only",
                    cores = 2,
                    chains = 2)

#prior check for both priors
pp_check(model_eb3_prior, nsamples = 100) #Doing a predictive prior check to test priors

#model
model_eb3 <- brm(hostile_score ~ gender*benevolent_score + (1|ID),
                    data = data_eb,
                    family = gaussian(),
                    prior = prior_eb3,
                    sample_prior = TRUE,
                    iter = 5000,
                    warmup = 2000,
                    cores = 4,
                    chains = 4, 
                    control = list(adapt_delta = 0.9))

summary(model_eb3)

#Plotting
marginal_effects(model_eb3)

plot(model_eb3)
```

##Hypothesis testing
```{r}
#Model 1
#There is no difference between females and males in overall sexism score
hypothesis(model_eb1.1, "genderMale = 0")


#Model 2
#There is no difference in benevolence score across gender
hypothesis(model_eb2, "genderMale = 0")

#There is no difference in benevolent score across gender as an effect of hostile score
hypothesis(model_eb2, "genderMale:hostile_score = 0")

#There is a correlation between benevolent score and hostile score
hypothesis(model_eb2, "hostile_score > 0")


#Model 3
#There is no difference in hostile score across gender
hypothesis(model_eb3, "genderMale = 0")

#There is no difference in hostile score across gender as an effect of benevolent score
hypothesis(model_eb3, "genderMale:benevolent_score = 0")

#There is a correlation between hostile score and benevolent score
hypothesis(model_eb3, "benevolent_score > 0")

```

##Plotting explicit bias

###H3.1.1
```{r prepare predictions}
nd_eb1.1 <- expand.grid(tibble(
         gender=factor(0:1) %>% 
           rep(., times = 10),
         ID = NA))

nd_eb1.1$gender <- ifelse(nd_eb1.1$gender == 0, "Male", "Female")

pred_eb1.1 <-
  predict(model_eb1.1, newdata = nd_eb1.1) %>%  # we can use the same nd data from last time
  as_tibble() %>%
  bind_cols(nd_eb1.1)

pred_eb1.1 <- pred_eb1.1 %>% group_by(gender) %>% summarise(mean_prediction = mean(Estimate))
```


```{r H3.1.1 plot}
#create the plot
H3.1.1 <- ggplot(data_eb, aes(x = gender, y = overall_score, fill = gender)) +
  labs(x = "Gender", y = "Overall Sexism Score", title = "Hypothesis 3.1.1") +
  geom_boxplot(aes(x = gender, overall_score) , data = data_eb, width = 0.5, alpha = 0.4) + 
  theme(legend.position = "none", panel.grid.minor = element_blank()) + 
  geom_point(aes(x = gender, y = mean_prediction), data = pred_eb1.1, size = 2) + 
  scale_fill_manual(values=c("orange", "blue")) +
  theme(plot.title = element_text(hjust = 0.5))
H3.1.1
```

###H3.2.1
```{r prepare predictions}
nd_eb1.1_2 <- expand.grid(tibble(
         gender=factor(0:1) %>% 
           rep(., times = 10),
         ID = NA, 
         hostile_score = NA))

nd_eb1.1_2$gender <- ifelse(nd_eb1.1_2$gender == 0, "Male", "Female")

#Inserting mean hostile score for the different gender
nd_eb1.1_2$hostile_score[nd_eb1.1_2$gender== "Male"] <- data_eb %>% filter(gender=="Male")%>% summarise(hostile_score = as.numeric(mean(hostile_score)))

nd_eb1.1_2$hostile_score[nd_eb1.1_2$gender== "Female"] <- data_eb %>% filter(gender=="Female")%>% summarise(hostile_score = as.numeric(mean(hostile_score)))

#Changing hostile score to numeric
nd_eb1.1_2$hostile_score <- as.numeric(nd_eb1.1_2$hostile_score)

pred_eb1.1_2 <-
  predict(model_eb2, newdata = nd_eb1.1_2) %>%  # we can use the same nd data from last time
  as_tibble() %>%
  bind_cols(nd_eb1.1_2)

pred_eb1.1_2 <- pred_eb1.1_2 %>% group_by(gender) %>% summarise(mean_prediction = mean(Estimate))
```


```{r H3.2.1 plot}
#create the plot
H3.2.1 <- ggplot(data_eb, aes(x = gender, y = benevolent_score, fill = gender)) +
  labs(x = "Gender", y = "Benevolent Score", title = "Hypothesis 3.2.1") +
  geom_boxplot(aes(x = gender, benevolent_score) , data = data_eb, width = 0.5, alpha = 0.4) + 
  theme(legend.position = "none", panel.grid.minor = element_blank()) + 
  geom_point(aes(x = gender, y = mean_prediction), data = pred_eb1.1_2, size = 2) + 
  scale_fill_manual(values=c("orange", "blue"))+
  theme(plot.title = element_text(hjust = 0.5))
H3.2.1
```


###H3.2.2
```{r prepare predictions}
nd_eb1.1_3 <- expand.grid(tibble(
         gender=factor(0:1) %>% 
           rep(., times = 3),
         ID = NA, 
         hostile_score = 0:5))

nd_eb1.1_3$gender <- ifelse(nd_eb1.1_3$gender == 0, "Male", "Female")

pred_eb1.1_3 <-
  predict(model_eb2, newdata = nd_eb1.1_3) %>%  # we can use the same nd data from last time
  as_tibble() %>%
  bind_cols(nd_eb1.1_3)

```


```{r H3.2.1 plot}
#create the plot
H3.2.2 <- ggplot(data_eb, aes(x = hostile_score, y = benevolent_score)) +
  labs(x = "Hostile Score", y = "Benevolent Score", title = "Hypothesis 3.2.2") +
  geom_point(aes(x = hostile_score, benevolent_score, color = gender) , data = data_eb) + 
  geom_smooth(aes(x = hostile_score, y = Estimate, color = gender), data = pred_eb1.1_3) + 
    scale_color_manual(values=c("orange", "blue"))+
  theme(plot.title = element_text(hjust = 0.5)) 

H3.2.2$labels$colour <- "Gender"

H3.2.2
```

###H3.2.3
```{r prepare predictions}
nd_eb1.1_4 <- expand.grid(tibble(
         gender=factor(0:1) %>% 
           rep(., times = 3),
         ID = NA, 
         hostile_score = 0:5))

nd_eb1.1_4$gender <- ifelse(nd_eb1.1_4$gender == 0, "Male", "Female")


pred_eb1.1_4 <-
  predict(model_eb2, newdata = nd_eb1.1_4) %>%  # we can use the same nd data from last time
  as_tibble() %>%
  bind_cols(nd_eb1.1_4)

```


```{r H3.2.3 plot}
#create the plot
H3.2.3 <- ggplot(data_eb, aes(x = hostile_score, y = benevolent_score)) +
  labs(x = "Hostile Score", y = "Benevolent Score", title = "Hypothesis 3.2.3") +
  geom_point(aes(x = hostile_score, benevolent_score) , data = data_eb) + 
  geom_smooth(aes(x = hostile_score, y = Estimate), data = pred_eb1.1_4) + 
    scale_color_manual(values=c("orange", "blue"))+
  theme(plot.title = element_text(hjust = 0.5)) 

H3.2.3$labels$colour <- "Gender"

H3.2.3
```

###H3.3.1
```{r prepare predictions}
nd_eb1.1_5 <- expand.grid(tibble(
         gender=factor(0:1) %>% 
           rep(., times = 10),
         ID = NA, 
         benevolent_score = NA))

nd_eb1.1_5$gender <- ifelse(nd_eb1.1_5$gender == 0, "Male", "Female")

#Inserting mean hostile score for the different gender
nd_eb1.1_5$benevolent_score[nd_eb1.1_2$gender== "Male"] <- data_eb %>% filter(gender=="Male")%>% summarise(benevolent_score = as.numeric(mean(benevolent_score)))

nd_eb1.1_5$benevolent_score[nd_eb1.1_2$gender== "Female"] <- data_eb %>% filter(gender=="Female")%>% summarise(benevolent_score = as.numeric(mean(benevolent_score)))

#Changing hostile score to numeric
nd_eb1.1_5$benevolent_score <- as.numeric(nd_eb1.1_5$benevolent_score)

pred_eb1.1_5 <-
  predict(model_eb3, newdata = nd_eb1.1_5) %>%  # we can use the same nd data from last time
  as_tibble() %>%
  bind_cols(nd_eb1.1_5)

pred_eb1.1_5 <- pred_eb1.1_5 %>% group_by(gender) %>% summarise(mean_prediction = mean(Estimate))
```


```{r H3.3.1 plot}
#create the plot
H3.3.1 <- ggplot(data_eb, aes(x = gender, y = hostile_score, fill = gender)) +
  labs(x = "Gender", y = "Hostile Score", title = "Hypothesis 3.3.1") +
  geom_boxplot(aes(x = gender, hostile_score) , data = data_eb, width = 0.5, alpha = 0.4) + 
  theme(legend.position = "none", panel.grid.minor = element_blank()) + 
  geom_point(aes(x = gender, y = mean_prediction), data = pred_eb1.1_5, size = 2) + 
  scale_fill_manual(values=c("orange", "blue"))+
  theme(plot.title = element_text(hjust = 0.5))
H3.3.1
```


###H3.3.2
```{r prepare predictions}
nd_eb1.1_6 <- expand.grid(tibble(
         gender=factor(0:1) %>% 
           rep(., times = 3),
         ID = NA, 
         benevolent_score = 0:5))

nd_eb1.1_6$gender <- ifelse(nd_eb1.1_6$gender == 0, "Male", "Female")

pred_eb1.1_6 <-
  predict(model_eb3, newdata = nd_eb1.1_6) %>%  # we can use the same nd data from last time
  as_tibble() %>%
  bind_cols(nd_eb1.1_6)

```


```{r H3.3.2 plot}
#create the plot
H3.3.2 <- ggplot(data_eb, aes(x = benevolent_score, y = hostile_score)) +
  labs(x = "Benevolent Score", y = "Hostile Score", title = "Hypothesis 3.3.2") +
  geom_point(aes(x = benevolent_score, hostile_score, color = gender) , data = data_eb) + 
  geom_smooth(aes(x = benevolent_score, y = Estimate, color = gender), data = pred_eb1.1_6) + 
    scale_color_manual(values=c("orange", "blue"))+
  theme(plot.title = element_text(hjust = 0.5)) 

H3.3.2$labels$colour <- "Gender"

H3.3.2
```

###H3.3.3
```{r prepare predictions}
nd_eb1.1_7 <- expand.grid(tibble(
         gender=factor(0:1) %>% 
           rep(., times = 3),
         ID = NA, 
         benevolent_score = 0:5))

nd_eb1.1_7$gender <- ifelse(nd_eb1.1_7$gender == 0, "Male", "Female")


pred_eb1.1_7 <-
  predict(model_eb3, newdata = nd_eb1.1_7) %>%  # we can use the same nd data from last time
  as_tibble() %>%
  bind_cols(nd_eb1.1_7)

```


```{r H3.3.3 plot}
#create the plot
H3.3.3 <- ggplot(data_eb, aes(x = benevolent_score, y = hostile_score)) +
  labs(x = "Benevolent Score", y = "Hostile Score", title = "Hypothesis 3.3.3") +
  geom_point(aes(x = benevolent_score, hostile_score) , data = data_eb) + 
  geom_smooth(aes(x = benevolent_score, y = Estimate), data = pred_eb1.1_7) + 
    scale_color_manual(values=c("orange", "blue"))+
  theme(plot.title = element_text(hjust = 0.5)) 

H3.3.3$labels$colour <- "Gender"

H3.3.3
```

#DECISION BIAS
Below are models: Firstly, the reconstructon of the model and the results from last year. Secondly, new combinations of the variables with the goal of finding the best model. 

###Analysis from last year (excluding skill difference)

```{r model excluding skill dif, replication of effects from last year, 1}

#Defining priors
prior_db1 <- c(
  prior(normal(0,.2),class="b"),
  prior(normal(0,.1),class="sd")
)

#prior predictive check
model_db1_prior <- brm(leader_behavior ~ 0 + Leader_gender:Follower_gender + (0 + skill_dif_roll_c:Follower_gender | SubjectID), 
                       prior = prior_db1, 
                       data = data_db, 
                       sample_prior = "only",
                       iter = 4000, 
                       family = "bernoulli", 
                       chains = 2, 
                       cores = 2)

pp_check(model_db1_prior, nsamples = 100)


model_db1 <- brm(
  leader_behavior ~ 0 + Leader_gender : Follower_gender + ( 0 + skill_dif_roll_c : Follower_gender | SubjectID),
  data = data_db,
  prior = prior_db1,
  sample_prior=T,
  family = "bernoulli", #As we had a binary outcome, we set this to "bernoulli"
  seed = 123, # Adding a seed makes results reproducible.
  chains=4,
  cores=4
  #control = list(adapt_delta = 0.9) 
) 
summary(model_db1)
```

##New models
```{r full model, 2}
#Defining priors 
prior_db2 <- c( 
  prior(normal(0,.2),class="b"),
  prior(normal(0,.1),class="sd")
)

#prior predictive check
model_db2_prior <- brm(leader_behavior ~ 0 + conf_dif_c*skill_dif_roll_c*Leader_gender:Follower_gender + (0 + skill_dif_roll_c:Follower_gender | SubjectID), 
                       prior = prior_db2, 
                       data = data_db, 
                       sample_prior = "only",
                       iter = 4000, 
                       family = "bernoulli", 
                       chains = 2, 
                       cores = 2)

pp_check(model_db2_prior, nsamples = 100)


model_db2 <- brm(leader_behavior ~ 1 + Follower_gender + conf_dif_c*skill_dif_roll_c*Leader_gender:Follower_gender + (1 + Follower_gender + skill_dif_roll_c:Follower_gender | SubjectID),
  data = data_db,
  prior = prior_db2,
  sample_prior=T,
  family = "bernoulli", #As we had a binary outcome, we set this to "bernoulli"
  seed = 123, # Adding a seed makes results reproducible.
  chains=4,
  cores=4
  #control = list(adapt_delta = 0.9) 
) 
marginal_effects(model_db2)

summary(model_db2) 


```


```{r model for extracting decision bias per ID}
model_db2_ID <- brm(leader_behavior ~ 1 + Follower_gender + (conf_dif_c+skill_dif_roll_c):Follower_gender + (1 + Follower_gender + (conf_dif_c+skill_dif_roll_c):Follower_gender | SubjectID),
  data = data_db,
  prior = prior_db2,
  sample_prior=T,
  family = "bernoulli", #As we had a binary outcome, we set this to "bernoulli"
  seed = 123, # Adding a seed makes results reproducible.
  chains=4,
  cores=4
  #control = list(adapt_delta = 0.9) 
) 
```



```{r model without confidence, 3}
#Defining priors
prior_db3 <- c(
  prior(normal(0,.2),class="b"),
  prior(normal(0,.1),class="sd")
)

#prior predictive check
model_db3_prior <- brm(leader_behavior ~ 0 + skill_dif_roll_c*Leader_gender:Follower_gender+ (0 + skill_dif_roll_c:Follower_gender | SubjectID), 
                       prior = prior_db3, 
                       data = data_db, 
                       sample_prior = "only",
                       iter = 4000, 
                       family = "bernoulli", 
                       chains = 2, 
                       cores = 2)

pp_check(model_db3_prior, nsamples = 100)


model_db3 <- brm(leader_behavior ~ 0 +skill_dif_roll_c*Leader_gender:Follower_gender+ (0 + skill_dif_roll_c:Follower_gender | SubjectID),
  data = data_db,
  prior = prior_db3,
  sample_prior=T,
  family = "bernoulli", #As we had a binary outcome, we set this to "bernoulli"
  seed = 123, # Adding a seed makes results reproducible.
  chains=4,
  cores=4
  #control = list(adapt_delta = 0.9) 
) 
summary(model_db3)
```

```{r model without skill difference, 4}
#Defining priors
prior_db4 <- c(
  prior(normal(0,.2),class="b"),
  prior(normal(0,.1),class="sd")
)

#prior predictive check
model_db4_prior <- brm(leader_behavior ~ 0 + conf_dif_c*Leader_gender:Follower_gender+ (0 + skill_dif_roll_c:Follower_gender | SubjectID), 
                       prior = prior_db4, 
                       data = data_db, 
                       sample_prior = "only",
                       iter = 4000, 
                       family = "bernoulli", 
                       chains = 2, 
                       cores = 2)

pp_check(model_db4_prior, nsamples = 100)


model_db4 <- brm(leader_behavior ~ 0 +conf_dif_c*Leader_gender:Follower_gender+ (0 + skill_dif_roll_c:Follower_gender | SubjectID),
  data = data_db,
  prior = prior_db4,
  sample_prior=T,
  family = "bernoulli", #As we had a binary outcome, we set this to "bernoulli"
  seed = 123, # Adding a seed makes results reproducible.
  chains=4,
  cores=4
  #control = list(adapt_delta = 0.9) 
) 
summary(model_db4)
```

#Colonmodel...

```{r}
model_db4.1 <- brm(leader_behavior ~ 0 +conf_dif_c:Leader_gender:Follower_gender+ (0 + skill_dif_roll_c:Follower_gender | SubjectID),
  data = data_db,
  prior = prior_db4,
  sample_prior=T,
  family = "bernoulli", #As we had a binary outcome, we set this to "bernoulli"
  seed = 123, # Adding a seed makes results reproducible.
  chains=4,
  cores=4
  #control = list(adapt_delta = 0.9) 
) 
summary(model_db4.1)
```




##Investigating confidence variable
```{r}
#add column with absolute response
data_db_all$Response_abs <- abs(data_db_all$Response)

get_prior(Response_abs ~ Gender*Partner_gender + (1 | SubjectID), family = "gaussian",
                       data = data_db_all)
#Defining priors 
prior_db5 <- c( 
  prior(student_t(3, 2, 10),class="Intercept"),
  prior(normal(0,.2),class="b"),
  prior(student_t(3, 0, 10),class="sd")
)

#prior predictive check
model_db5_prior <- brm(Response_abs ~ Gender*Partner_gender+ (1 | SubjectID), 
                       prior = prior_db5, 
                       data = data_db_all, 
                       sample_prior = "only",
                       iter = 4000, 
                       family = "gaussian", 
                       chains = 2, 
                       cores = 2)

pp_check(model_db5_prior, nsamples = 100)


model_db5 <- brm(Response_abs ~ Gender*Partner_gender + (1 | SubjectID),
  data = data_db_all,
  prior = prior_db5,
  sample_prior=T,
  family = "gaussian", #As we had a binary outcome, we set this to "bernoulli"
  seed = 123, # Adding a seed makes results reproducible.
  chains=6,
  cores=4,
  control = list(adapt_delta = 0.99) 
) 
marginal_effects(model_db5)

summary(model_db5)

```

##Investigating skill difference
```{r is men better than women regression, include = FALSE}

#Defining priors
prior_db6 <- c(
  prior(normal(0, 0.2),class="Intercept"),
  prior(normal(0,0.1),class="b"),
  prior(normal(0,0.2), class= "sd")
)


#prior predictive check
model_db6_prior <- brm(response_dummy ~ diff*Gender + (1+diff|SubjectID), 
                       prior = prior_db6, 
                       data = data_db_all, 
                       sample_prior = "only",
                       iter = 4000, 
                       family = "bernoulli", 
                       chains = 2, 
                       cores = 2)

pp_check(model_db6_prior, nsamples = 100)

# Model answer predicted by gender and difficulty
model_db6 <- brm(
  response_dummy ~ diff*Gender + (1+diff|SubjectID), 
  data = data_db_all,
  prior = prior_db6,
  family = "bernoulli",
  sample_prior=T,
  seed = 123, # Adding a seed makes results reproducible.
  cores=4,
  chains=4
) 


# Model answer predicted by gender and difficulty
model_db7 <- brm(
  response_dummy ~ diff:Gender + (1+diff|SubjectID), 
  data = data_db_all,
  prior = prior_db6,
  family = "bernoulli",
  sample_prior=T,
  seed = 123, # Adding a seed makes results reproducible.
  cores=4,
  chains=4
) 


##MODELLING SKILL FROM CORRECT

#Model predicting correctness from gender
model_db8 <- brm(
  Correct ~ Gender + (1+diff|SubjectID), 
  data = data_db_all,
  prior = prior_db6,
  family = "bernoulli",
  sample_prior=T,
  seed = 123, # Adding a seed makes results reproducible.
  cores=4,
  chains=4
) 


```

##Waic
```{r waic}
waic(model_db1, model_db2, model_db3, model_db4)


```

## Hypothesis testing


##Are men better than women? 
```{r}
#model db6 with star
hypothesis(model_db6, "diff = (diff+diff:GenderMale)")

#model db7 with colon 
hypothesis(model_db7, "diff:GenderFemale < diff:GenderMale")
```


##Are females more discriminative towards their partner gender in terms of confidence?
```{r}
#model db5 
hypothesis(model_db5, "(Intercept - (Intercept + Partner_genderMale)) > ((Intercept + GenderMale) -  (Intercept + GenderMale:Partner_genderMale))")


```

##Males generally express higher confidence than females

```{r}
#model db5
hypothesis(model_db5, "((Intercept + (Intercept + Partner_genderMale)) / 2) < (((Intercept + GenderMale) + (Intercept + GenderMale:Partner_genderMale))/2)")
```

##Males exploit the information given by the confidence of their partner more than females, when making a final decision
```{r}
#testing this hypothsis with model_db2
hypothesis(model_db2, "((conf_dif_c:Leader_genderFemale:Follower_genderFemale + conf_dif_c:Leader_genderFemale:Follower_genderMale)/2) > ( (conf_dif_c:Leader_genderMale:Follower_genderFemale + conf_dif_c:Leader_genderMale:Follower_genderMale)/2) ")

```

##Females are more discriminative to their follower's gender in terms of the degree to which they exploit the information given by their partner's confidence than males
```{r}

hypothesis(model_db2, "(conf_dif_c:Leader_genderFemale:Follower_genderMale - conf_dif_c:Leader_genderFemale:Follower_genderFemale) > ( conf_dif_c:Leader_genderMale:Follower_genderMale - conf_dif_c:Leader_genderMale:Follower_genderFemale) ")


```


##Males exploit the information given by the skill of their partner more than females, when making a final decision
```{r}
#testing this hypothsis with model_db2
hypothesis(model_db2, "((skill_dif_c:Leader_genderFemale:Follower_genderFemale + skill_dif_c:Leader_genderFemale:Follower_genderMale)/2) > ( (skill_dif_c:Leader_genderMale:Follower_genderFemale + skill_dif_c:Leader_genderMale:Follower_genderMale)/2) ")

```

##Females are more discriminative to their follower's gender in terms of the degree to which they exploit the information given by their partner's skill than males
```{r}

hypothesis(model_db2, "(skill_dif_c:Leader_genderFemale:Follower_genderMale - skill_dif_c:Leader_genderFemale:Follower_genderFemale) < ( skill_dif_c:Leader_genderMale:Follower_genderMale - skill_dif_c:Leader_genderMale:Follower_genderFemale) ")


```



###For the simple model (excluding skill difference and confidence difference)
H1: there is a leader effect: male leaders tend to surrender less than female leaders
```{r H1: there is a leader effect: male leaders tend to surrender less than female leaders}
#H1: In general male leader tend to surrender less than female leaders

hypothesis(model_db2, "(Leader_genderMale:Follower_genderMale + Leader_genderMale:Follower_genderFemale)/2 < (Leader_genderFemale:Follower_genderMale + Leader_genderFemale:Follower_genderMale)/2")

```

H2: there is a follower effect: leaders tend to surrender more to men than to women
```{r H2: there is a follower effect: leaders tend to surrender more to men than to women }

# H2: There is a follower effect: leaders tend to surrender more to men than to women
hypothesis(model_db2, "(Leader_genderMale:Follower_genderMale + Leader_genderFemale:Follower_genderMale)/2 > (Leader_genderMale:Follower_genderFemale + Leader_genderFemale:Follower_genderFemale)/2")


```

H3: There is an interaction: Females are more discriminative as to their followers gender than males are
```{r H3: there is an interaction, females are more discriminative as to their followers gender than males are }

hypothesis(model_db2, "(Leader_genderMale:Follower_genderMale - Leader_genderMale:Follower_genderFemale) < (Leader_genderFemale:Follower_genderMale - Leader_genderFemale:Follower_genderFemale)")


```


###For the complex model
```{r}
#H1.1: Leaders are less prone to surrender as a product of higher confidence difference i.e. the more higher confidence the leader has and lower confidence the follower has the less prone the leader is to surrender

hypothesis(model_db2, "conf_dif < 0")

#H1.2: Leaders are less prone to surrender as a product of higher skill difference i.e. the more higher skill the leader has and lower skill the follower has the less prone the leader is to surrender

hypothesis(model_db2, "skill_dif < 0")

#H1.3 In general male leader tend to surrender less than female leaders

hypothesis(model_db2, "(Leader_genderMale:Follower_genderMale + Leader_genderMale:Follower_genderFemale)/2 < (Leader_genderFemale:Follower_genderMale + Leader_genderFemale:Follower_genderMale)/2")

#H1.4 There is a follower effect: leaders tend to surrender more to men than to women

hypothesis(model_db2, "(Leader_genderMale:Follower_genderMale + Leader_genderFemale:Follower_genderMale)/2 > (Leader_genderMale:Follower_genderFemale + Leader_genderFemale:Follower_genderFemale)/2")

#H3: There is an interaction: males are more discriminative as to their followers gender than females are

hypothesis(model_db2, "(Leader_genderMale:Follower_genderMale - Leader_genderMale:Follower_genderFemale) > (Leader_genderFemale:Follower_genderMale - Leader_genderFemale:Follower_genderFemale)")

```



##Plotting

Model_db1
Leader behavior ~ 0 + Leader gender:Follower gender + (0 + skill difference : Follower gender | Subject)


```{r}
nd_db1 <- expand.grid(tibble(
         Follower_gender=factor(0:2) %>% rep(., times = 10),
         Leader_gender = factor(0:2) %>% rep(., times = 10),
         SubjectID = NA))



nd_db1$Follower_gender <- ifelse(nd_db1$Follower_gender == 0, "Male", "Female")

nd_db1$Leader_gender <- ifelse(nd_db1$Leader_gender == 0, "Male", "Female")


pred_db1 <-
  predict(model_db1, newdata = nd_db1, re_formula = ~ (0 + skill_dif_roll_c:Follower_gender | SubjectID)) %>%
  as_tibble() %>%
  bind_cols(nd_db1)

```


#H1.1.1: In general, male leaders tend to surrender less than female leaders.

```{r}
#create the plot
H1.1.1 <- ggplot(data_db, aes(x = Leader_gender, y = leader_behavior, fill = Leader_gender)) +
  labs(x = "Leader gender", y = "Predicted propensity to surrender", title = "H1.1.1") +
  geom_boxplot(aes(x = Leader_gender, Estimate) , data = pred_db1, width = 0.5) + 
  theme(legend.position = "none", panel.grid.minor = element_blank()) + 
  geom_violin(aes(x = Leader_gender, y = Estimate), data = pred_db1, trim = FALSE, width =1, alpha = 0.1) + 
  scale_y_continuous(breaks = sort(c(seq(min(pred_db1$Estimate), max(pred_db1$Estimate), length.out=5), 0.5))) + 
  geom_hline(yintercept= 0.5, color = "black", linetype = "dashed", alpha = 0.8) + 
  scale_fill_manual(values=c("orange", "blue"))

H1.1.1

```

#H1.1.2: Leaders tend to surrender more to male followers than to female followers

```{r}
H1.1.2 <- ggplot(data_db, aes(x = Follower_gender, y = leader_behavior, fill = Follower_gender)) +
  labs(x = "Follower gender", y = "Predicted propensity to surrender", title = "H1.1.2") +
  geom_boxplot(aes(x = Follower_gender, Estimate) , data = pred_db1, width = 0.5) + 
  theme(legend.position = "none", panel.grid.minor = element_blank()) + 
  geom_violin(aes(x = Follower_gender, y = Estimate), data = pred_db1, trim = FALSE, width =1, alpha = 0.1) + 
  scale_y_continuous(breaks = sort(c(seq(min(pred_db1$Estimate), max(pred_db1$Estimate), length.out=5), 0.5))) + 
  geom_hline(yintercept= 0.5, color = "black", linetype = "dashed", alpha = 0.8) + 
  scale_fill_manual(values=c("orange", "blue"))

H1.1.2

```


#H1.1.3: Females are more discriminative towards their follower’s gender than males are, i.e. for female leaders, the gender of the follower makes a larger difference to their decision than it does for male leaders.

```{r}
H1.1.3 <- ggplot(pred_db1, aes(x = Leader_gender, y = Estimate, fill = Follower_gender)) + 
  geom_violin(aes(x = Leader_gender, y = Estimate), data = pred_db1, width = 0.7, alpha = 0.8) + 
  geom_hline(yintercept= 0.5, color = "black", linetype = "dashed", alpha = 0.8) + 
  scale_y_continuous(breaks = sort(c(seq(min(pred_db1$Estimate), max(pred_db1$Estimate), length.out=5), 0.5))) + 
  theme(panel.grid.minor = element_blank()) + 
  labs(x = "Leader gender", y = "Predicted propensity to surrender", title = "H1.1.3") + 
  stat_summary(fun.data=mean_sdl, geom="pointrange", color="black", position = position_dodge(width = 0.7), alpha = 0.8) +
  labs(fill = "Follower gender") + 
  scale_fill_manual(values=c("orange", "blue"))

H1.1.3

```





##Look into confidence variable 

```{r}
conf_plot <- ggplot(data_db, aes(x=Leader_gender, y=conf_dif_c, fill = Follower_gender)) + geom_boxplot() + facet_wrap(~Leader_gender)
conf_plot


plot1 <- ggplot(data_db, aes(x=conf_dif_c, y = leader_behavior, fill = Leader_gender)) + geom_point() + facet_wrap(~Leader_gender)
plot1


```

```{r prepare predictions}
nd <- expand.grid(tibble(
         Follower_gender=factor(0:1) %>% rep(., times = 10),
         Leader_gender = factor(0:1) %>% rep(., times = 10),
         conf_dif = factor((4/1-1), (4/2-1),(4/3-1), 0, (3/1-1), (3/2-1), (3/4-1), (2/3-1), (2/4-1), (1/3-1), (1/4-1)) %>% rep(., times = 10),
         SubjectID = NA))

nd <- expand.grid(tibble(
         Follower_gender=seq(0:2) %>% rep(., times = 10),
         Leader_gender = factor(0:2) %>% rep(., times = 10),
         SubjectID = NA))



nd$Follower_gender <- ifelse(nd$Follower_gender == 0, "Male", "Female")

nd$Leader_gender <- ifelse(nd$Leader_gender == 0, "Male", "Female")


pred <-
  predict(model_db1, newdata = nd, re_formula = ~ (0 + Follower_gender | SubjectID)) %>%  # we can use the same nd data from last time
  as_tibble() %>%
  bind_cols(nd)
```


```{r H1 plot}
#create the plot
H1 <- ggplot(disagree_db_long, aes(x = Leader_gender, y = leader_behavior, fill = Leader_gender)) +
  labs(x = "Leader gender", y = "Predicted propensity to surrender", title = "Hypothesis 1") +
  geom_boxplot(aes(x = Leader_gender, Estimate) , data = pred, width = 0.5) + 
  theme(legend.position = "none", panel.grid.minor = element_blank()) + 
  geom_violin(aes(x = Leader_gender, y = Estimate), data = pred, trim = FALSE, width =1, alpha = 0.1) + 
  scale_y_continuous(breaks = sort(c(seq(min(pred$Estimate), max(pred$Estimate), length.out=5), 0.5))) + 
  geom_hline(yintercept= 0.5, color = "black", linetype = "dashed", alpha = 0.8) + 
  scale_fill_manual(values=c("palegreen3", "gold2"))
H1
```


```{r H2: plotting}

#create the plot
H2 <- ggplot(disagree_db_long, aes(x = Follower_gender, y = leader_behavior, fill = Follower_gender)) +
  labs(x = "Follower gender", y = "Predicted propensity to surrender", title = "Hypothesis 2") +
  geom_boxplot(aes(x = Follower_gender, Estimate) , data = pred, width = 0.5) + 
  theme(legend.position = "none", panel.grid.minor = element_blank()) + 
  geom_violin(aes(x = Follower_gender, y = Estimate), data = pred, trim = FALSE, width =1, alpha = 0.1) + 
  scale_y_continuous(breaks = sort(c(seq(min(pred$Estimate), max(pred$Estimate), length.out=5), 0.5))) + 
  geom_hline(yintercept= 0.5, color = "black", linetype = "dashed", alpha = 0.8) + 
  scale_fill_manual(values=c("palegreen3", "gold2"))

H2
```

H3: plotting
```{r H3.1 plotting}
marginal_effects(model_db1)

#create the plot
H3.1 <- ggplot(disagree_db_long, aes(x = Leader_gender, y = leader_behavior, fill = Follower_gender)) +
  labs(x = "Leader gender", y = "Predicted propensity to surrender", title = "Hypothesis 3 - Boxplot") +
  geom_boxplot(aes(x = Leader_gender, Estimate, fill = Follower_gender) , data = pred, width = 0.5, alpha = 0.8) + 
  labs(fill = "Follower gender") +
  theme(panel.grid.minor = element_blank()) +
  scale_y_continuous(breaks = sort(c(seq(min(pred$Estimate), max(pred$Estimate), length.out=5)))) +
  scale_fill_manual(values=c("palegreen3", "gold2"))

H3.1

```

```{r H3.2 Plotting}
H3.2 <- ggplot(pred, aes(x = Leader_gender, y = Estimate, fill = Follower_gender)) + 
  geom_violin(aes(x = Leader_gender, y = Estimate), data = pred, width = 0.7, alpha = 0.8) + 
  geom_hline(yintercept= 0.5, color = "black", linetype = "dashed", alpha = 0.8) + 
  scale_y_continuous(breaks = sort(c(seq(min(pred$Estimate), max(pred$Estimate), length.out=5), 0.5))) + 
  theme(panel.grid.minor = element_blank()) + 
  labs(x = "Leader gender", y = "Predicted propensity to surrender", title = "Hypothesis 3") + 
  stat_summary(fun.data=mean_sdl, geom="pointrange", color="black", position = position_dodge(width = 0.7), alpha = 0.8) +
  labs(fill = "Follower gender") + 
  scale_fill_manual(values=c("palegreen3", "gold2"))
```
 

#GENDER BIAS

Lav modeller, der kombinerer data fra de tre forskellige dele. 






